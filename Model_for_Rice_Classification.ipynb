{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Model for Rice Classification",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralik45/Rice-Classification/blob/main/Model_for_Rice_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'rice-image-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2049052%2F3399185%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240810%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240810T092404Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D44e9fa1d3057f2bdf8138d56e05ee5e90e80beb3f5d109b3cb1d8312e135cbb1fd63a611f1aaafe237d49035636ebfcae7f66dc47b8b1043f81c18f93d7615fe8444ed359506de08555b237d9901dc49bb895fc911a06623bc1ab0b1cba6c4031935fb91613cba89dc7f9f59a32eec2f4d5b95f60f3ffd9750ad2f73e0c1f7cf1eacd77c2141233e34ffec7edc74e7de4eb7b6010b7063092d31732eed1f527253508db548a04ae6fc1e3404ea5125d2a8df985220d1eedc90a566b36f02aa66c522a56f1e88f74bf32743712baa699b2ff40a9a66bd0df98ec77446b457a6750bb083c231b4c879543cbf4d2f358e04435a9af187ce1de401f6fd7845f653a0,testing-rice:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3399927%2F5920253%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240810%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240810T092404Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0ead01328947acb8f9e35ae75d39fd4fa170eb83db7519d8ae2719c887b72f0630b5c7898d55fecd3c4abf05b62bb5d72af115b2ba8d5b0d3f4de73b15dafc72e3e2f1db5331619b1aca676a9c5551f8696256b0ddfd4938fa43b10f199063c7ff919642d1889b84767641b72387b2d9a13fbdbbe7ada1f63dc3d59819fdc16d1dc2b6ce7ae6d69d8d52f057373bd8d5a2e7055f2ebe5173abf93288f6547355a09a35f9178e442bb1da78d2716d1e6ec65d74e7991dba3abcfdcde488971bdde0cd3f6b85dc1af7dae11b74607b475a13576f93914b091b4344bca51f3e949949b706cdef011a90bb8bc9072a13066d122ff7dc354b96422d40fb7fd7494537'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "YRvldvxvmj1K"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "lPMJccOVmj1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model, callbacks\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Convolution2D,Activation,Flatten,Dense,Dropout,MaxPool2D,BatchNormalization"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-06-13T11:26:24.148542Z",
          "iopub.execute_input": "2023-06-13T11:26:24.149043Z",
          "iopub.status.idle": "2023-06-13T11:26:24.160463Z",
          "shell.execute_reply.started": "2023-06-13T11:26:24.149001Z",
          "shell.execute_reply": "2023-06-13T11:26:24.159557Z"
        },
        "trusted": true,
        "id": "2xIJS0aUmj1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "L9p88ryQmj1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset'\n",
        "image_classes = os.listdir(dataset)\n",
        "image_classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T10:17:24.534872Z",
          "iopub.execute_input": "2023-06-13T10:17:24.535624Z",
          "iopub.status.idle": "2023-06-13T10:17:24.560299Z",
          "shell.execute_reply.started": "2023-06-13T10:17:24.535587Z",
          "shell.execute_reply": "2023-06-13T10:17:24.559427Z"
        },
        "trusted": true,
        "id": "ULd_luZOmj1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rice_types = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
        "images = []\n",
        "\n",
        "fig, axs = plt.subplots(1, len(rice_types), figsize=(15, 5))\n",
        "\n",
        "for i, rice_type in enumerate(rice_types):\n",
        "    img = cv2.imread(f'/kaggle/input/rice-image-dataset/Rice_Image_Dataset/{rice_type}/{rice_type} (1).jpg')\n",
        "    images.append(img)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title(rice_type)\n",
        "    print(img.shape)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T10:33:44.281448Z",
          "iopub.execute_input": "2023-06-13T10:33:44.281823Z",
          "iopub.status.idle": "2023-06-13T10:33:45.007931Z",
          "shell.execute_reply.started": "2023-06-13T10:33:44.281794Z",
          "shell.execute_reply": "2023-06-13T10:33:45.00704Z"
        },
        "trusted": true,
        "id": "Jc5fy_TZmj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataGenerator = ImageDataGenerator(rescale= 1. / 255, validation_split=0.2)\n",
        "train_data = dataGenerator.flow_from_directory(\n",
        "    dataset,\n",
        "    target_size=(250,250),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        ")\n",
        "val_data = dataGenerator.flow_from_directory(\n",
        "    dataset,\n",
        "    target_size=(250,250),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T12:47:13.324305Z",
          "iopub.execute_input": "2023-06-13T12:47:13.324668Z",
          "iopub.status.idle": "2023-06-13T12:47:16.190388Z",
          "shell.execute_reply.started": "2023-06-13T12:47:13.324638Z",
          "shell.execute_reply": "2023-06-13T12:47:16.189396Z"
        },
        "trusted": true,
        "id": "k2eppQtcmj1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "G32gOx8xmj1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "aDpxN0RAmj1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNN = Sequential()\n",
        "\n",
        "CNN.add(Conv2D(64, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(Conv2D(128, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(MaxPool2D(pool_size=(3, 3)))\n",
        "\n",
        "CNN.add(Conv2D(128, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(Conv2D(128, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "\n",
        "CNN.add(Conv2D(256, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(MaxPool2D(pool_size=(3, 3)))\n",
        "\n",
        "CNN.add(Conv2D(512, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(MaxPool2D(pool_size=(3, 3)))\n",
        "\n",
        "CNN.add(Conv2D(512, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "\n",
        "CNN.add(Conv2D(512, kernel_size=(3,3), padding='same', input_shape = (250,250,3)))\n",
        "CNN.add(BatchNormalization())\n",
        "CNN.add(Activation('relu'))\n",
        "CNN.add(MaxPool2D(pool_size=(3, 3)))\n",
        "\n",
        "CNN.add(Flatten())\n",
        "CNN.add(Dense(256, activation='relu'))\n",
        "CNN.add(Dropout(0.1))\n",
        "CNN.add(Dense(256, activation='relu'))\n",
        "CNN.add(Dropout(0.1))\n",
        "CNN.add(Dense(5, activation='softmax'))\n",
        "\n",
        "CNN.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T10:49:05.814571Z",
          "iopub.execute_input": "2023-06-13T10:49:05.815615Z",
          "iopub.status.idle": "2023-06-13T10:49:06.158884Z",
          "shell.execute_reply.started": "2023-06-13T10:49:05.815581Z",
          "shell.execute_reply": "2023-06-13T10:49:06.158129Z"
        },
        "trusted": true,
        "id": "CrcWQaNgmj1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T10:49:06.15996Z",
          "iopub.execute_input": "2023-06-13T10:49:06.160579Z",
          "iopub.status.idle": "2023-06-13T10:49:06.185489Z",
          "shell.execute_reply.started": "2023-06-13T10:49:06.160544Z",
          "shell.execute_reply": "2023-06-13T10:49:06.184811Z"
        },
        "trusted": true,
        "id": "ZE6wIfWxmj1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "gYFNrGhTmj1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_cb = callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                              factor=0.2,\n",
        "                                              patience=2,\n",
        "                                              verbose=1,\n",
        "                                              min_lr=1e-7)\n",
        "\n",
        "checkpoint_path = \"./Checkpoint/\"\n",
        "model_checkpoint = callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                      save_weights_only=True,\n",
        "                                                      save_best_only=True,\n",
        "                                                      monitor=\"val_loss\")\n",
        "\n",
        "history = CNN.fit(train_data,\n",
        "                    epochs=3,\n",
        "                    validation_data=val_data,\n",
        "                    callbacks=[early_stopping_cb, model_checkpoint, reduce_lr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T10:50:44.759298Z",
          "iopub.execute_input": "2023-06-13T10:50:44.759654Z",
          "iopub.status.idle": "2023-06-13T11:20:09.834334Z",
          "shell.execute_reply.started": "2023-06-13T10:50:44.759627Z",
          "shell.execute_reply": "2023-06-13T11:20:09.83324Z"
        },
        "trusted": true,
        "id": "Desvhs25mj1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "JBaoJeavmj1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss & Accuracy"
      ],
      "metadata": {
        "id": "wE-BcZ0Wmj1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(history_df):\n",
        "    plt.figure(figsize = (13, 4), dpi = 120)\n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, len(history_df) + 1), history_df['loss'], marker = '.', label = 'Training Loss')\n",
        "    plt.plot(range(1, len(history_df) + 1), history_df['val_loss'], marker = '^', label = 'Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Cross Entropy')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    ax = plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, len(history_df) + 1), history_df['accuracy'], marker = '.', label = 'Training Accuracy')\n",
        "    plt.plot(range(1, len(history_df) + 1), history_df['val_accuracy'], marker = '^', label = 'Validation Accurcay')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T11:56:41.871567Z",
          "iopub.execute_input": "2023-06-13T11:56:41.871964Z",
          "iopub.status.idle": "2023-06-13T11:56:41.882704Z",
          "shell.execute_reply.started": "2023-06-13T11:56:41.871927Z",
          "shell.execute_reply": "2023-06-13T11:56:41.881806Z"
        },
        "trusted": true,
        "id": "Y8Qk33tmmj1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_curves(pd.DataFrame(history.history))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T11:57:08.673214Z",
          "iopub.execute_input": "2023-06-13T11:57:08.673559Z",
          "iopub.status.idle": "2023-06-13T11:57:09.116596Z",
          "shell.execute_reply.started": "2023-06-13T11:57:08.673534Z",
          "shell.execute_reply": "2023-06-13T11:57:09.115641Z"
        },
        "trusted": true,
        "id": "f-ANgFEYmj1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Report"
      ],
      "metadata": {
        "id": "-CHs1fPgmj1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = val_data.class_indices\n",
        "li = list(class_dict.keys())\n",
        "print(li)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T11:51:10.073084Z",
          "iopub.execute_input": "2023-06-13T11:51:10.073438Z",
          "iopub.status.idle": "2023-06-13T11:51:10.078769Z",
          "shell.execute_reply.started": "2023-06-13T11:51:10.07341Z",
          "shell.execute_reply": "2023-06-13T11:51:10.077537Z"
        },
        "trusted": true,
        "id": "GJuZXX4_mj1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = CNN.predict(val_data)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print('Classification Report')\n",
        "target_names =li\n",
        "print(classification_report(val_data.classes, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T11:58:25.554772Z",
          "iopub.execute_input": "2023-06-13T11:58:25.555365Z",
          "iopub.status.idle": "2023-06-13T11:59:34.980046Z",
          "shell.execute_reply.started": "2023-06-13T11:58:25.555329Z",
          "shell.execute_reply": "2023-06-13T11:59:34.978981Z"
        },
        "trusted": true,
        "id": "twr0Y4svmj1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "qkn36Ax1mj1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize = (6,6), dpi = 100)\n",
        "sns.heatmap(confusion_matrix(val_data.classes, y_pred), annot = True, cmap = 'Reds')\n",
        "plt.xlabel('Predictions')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Conusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T11:55:11.444774Z",
          "iopub.execute_input": "2023-06-13T11:55:11.445475Z",
          "iopub.status.idle": "2023-06-13T11:55:11.800077Z",
          "shell.execute_reply.started": "2023-06-13T11:55:11.445437Z",
          "shell.execute_reply": "2023-06-13T11:55:11.799121Z"
        },
        "trusted": true,
        "id": "OEuBYo5jmj1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Images"
      ],
      "metadata": {
        "id": "PCs3kXYGmj1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from keras.models import load_model\n",
        "# Load the trained model\n",
        "model = CNN\n",
        "\n",
        "# Define the image size and preprocessing function\n",
        "img_size = (250, 250)\n",
        "def preprocess_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = img.resize(img_size)\n",
        "    img = np.array(img) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "# Set the path to the image folder\n",
        "test_dir = '/kaggle/input/testing-rice/test_dir'\n",
        "img_folder = test_dir\n",
        "class_names = list(train_data.class_indices.keys())\n",
        "# Loop through all the images in the folder and make predictions\n",
        "for filename in os.listdir(img_folder):\n",
        "    img_path = os.path.join(img_folder, filename)\n",
        "    img = preprocess_image(img_path)\n",
        "    pred = model.predict(img)\n",
        "    class_idx = np.argmax(pred)\n",
        "    class_name = class_names[class_idx]\n",
        "    print(f'Image: {filename}, Class: {class_name}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-13T13:30:19.652592Z",
          "iopub.execute_input": "2023-06-13T13:30:19.652987Z",
          "iopub.status.idle": "2023-06-13T13:30:21.716738Z",
          "shell.execute_reply.started": "2023-06-13T13:30:19.652958Z",
          "shell.execute_reply": "2023-06-13T13:30:21.714968Z"
        },
        "trusted": true,
        "id": "C92TXyoPmj1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ljUtWSimj1b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}